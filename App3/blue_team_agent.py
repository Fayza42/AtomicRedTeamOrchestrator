# Notebook 08: Agent Blue Team - Analyse D√©fensive et Rem√©diation
# Filename: notebook_08_agent_blue_team.ipynb

# %% [markdown]
"""
# Agent Blue Team - Analyse D√©fensive et Rem√©diation

## Capacit√©s D√©fensives :
- ‚úÖ Analyse des scripts d'exploitation du Red Team
- ‚úÖ Identification des indicateurs d'attaque (IoC/IoA) 
- ‚úÖ G√©n√©ration de recommandations de rem√©diation
- ‚úÖ Cr√©ation de r√®gles de d√©tection (SIEM, IDS, WAF)
- ‚úÖ Propositions de durcissement du syst√®me
- ‚úÖ M√©triques de s√©curit√© et KPI de risque

## Workflow :
1. **Input** : analysis_report.json + exploitation_report.json
2. **Analyse des Artefacts** : Examen du script d'exploit et des techniques
3. **Identification IoC/IoA** : Extraction des indicateurs d'attaque
4. **G√©n√©ration de D√©fenses** : R√®gles de d√©tection et de pr√©vention
5. **Plan de Rem√©diation** : Corrections √† court et long terme
6. **Output** : defense_report.json avec plan complet
"""

# %%
import os
import json
import re
import hashlib
from typing import Dict, List, Any, Optional, Set
from datetime import datetime, timedelta
from pathlib import Path
import subprocess

# Imports LangChain et Pydantic
from pydantic import BaseModel, Field, validator
from langchain.llms import Ollama
from langchain.embeddings import OllamaEmbeddings
from langchain.vectorstores import Chroma
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain.output_parsers import PydanticOutputParser

print("üîµ Initialisation de l'Agent Blue Team...")

# %%
# Mod√®les Pydantic pour l'Agent Blue Team
class IndicatorOfCompromise(BaseModel):
    """Mod√®le pour un indicateur de compromission"""
    
    ioc_type: str = Field(
        description="Type d'IoC (IP, URL, file_hash, process_name, etc.)"
    )
    
    value: str = Field(
        description="Valeur de l'indicateur"
    )
    
    severity: str = Field(
        description="S√©v√©rit√© (LOW, MEDIUM, HIGH, CRITICAL)"
    )
    
    description: str = Field(
        description="Description de l'indicateur et de son contexte"
    )
    
    detection_rule: str = Field(
        description="R√®gle de d√©tection associ√©e (Sigma, Snort, etc.)"
    )
    
    @validator('severity')
    def validate_severity(cls, v):
        allowed = ["LOW", "MEDIUM", "HIGH", "CRITICAL"]
        if v not in allowed:
            raise ValueError(f"severity doit √™tre dans {allowed}")
        return v

class DefenseRecommendation(BaseModel):
    """Mod√®le pour une recommandation d√©fensive"""
    
    category: str = Field(
        description="Cat√©gorie (PATCH, CONFIGURATION, MONITORING, NETWORK)"
    )
    
    priority: str = Field(
        description="Priorit√© (IMMEDIATE, HIGH, MEDIUM, LOW)"
    )
    
    title: str = Field(
        description="Titre court de la recommandation"
    )
    
    description: str = Field(
        description="Description d√©taill√©e de la recommandation"
    )
    
    implementation_steps: List[str] = Field(
        description="√âtapes d'impl√©mentation",
        default_factory=list
    )
    
    estimated_effort: str = Field(
        description="Effort estim√© (minutes, heures, jours)"
    )
    
    risk_reduction: int = Field(
        description="R√©duction du risque en pourcentage (0-100)",
        ge=0,
        le=100
    )

class DefenseReport(BaseModel):
    """Mod√®le pour le rapport de d√©fense complet"""
    
    attack_analysis: Dict[str, Any] = Field(
        description="Analyse de l'attaque du Red Team"
    )
    
    indicators_of_compromise: List[IndicatorOfCompromise] = Field(
        description="Indicateurs de compromission identifi√©s",
        default_factory=list
    )
    
    defense_recommendations: List[DefenseRecommendation] = Field(
        description="Recommandations de d√©fense",
        default_factory=list
    )
    
    detection_rules: Dict[str, List[str]] = Field(
        description="R√®gles de d√©tection par type (WAF, IDS, SIEM)",
        default_factory=dict
    )
    
    risk_assessment: Dict[str, Any] = Field(
        description="√âvaluation du risque et m√©triques",
        default_factory=dict
    )
    
    remediation_timeline: Dict[str, List[str]] = Field(
        description="Timeline de rem√©diation par priorit√©",
        default_factory=dict
    )

print("‚úÖ Mod√®les Pydantic pour Blue Team d√©finis")

# %%
# Analyseur de S√©curit√© pour les Scripts d'Exploitation
class SecurityAnalyzer:
    """Analyseur de s√©curit√© pour les scripts et techniques d'attaque"""
    
    def __init__(self):
        # Patterns d'attaque connus
        self.attack_patterns = {
            'command_injection': [
                r'system\s*\(',
                r'exec\s*\(',
                r'shell_exec\s*\(',
                r'eval\s*\(',
                r'os\.system',
                r'subprocess\.',
                r'cmd\s*/c',
                r'sh\s+-c'
            ],
            'reverse_shell': [
                r'/dev/tcp/',
                r'nc\s+-[lve]+',
                r'netcat',
                r'bash\s+-i',
                r'>& /dev/tcp',
                r'socket\.socket',
                r'subprocess\.call.*sh'
            ],
            'file_access': [
                r'\.\./',
                r'%2e%2e',
                r'/etc/passwd',
                r'/etc/shadow',
                r'file_get_contents',
                r'fopen\s*\(',
                r'readfile'
            ],
            'web_exploitation': [
                r'requests\.post',
                r'urllib\.request',
                r'curl\s+',
                r'wget\s+',
                r'<script>',
                r'javascript:',
                r'SQL.*UNION',
                r'DROP\s+TABLE'
            ],
            'persistence': [
                r'crontab',
                r'/etc/rc\.local',
                r'systemctl',
                r'service\s+',
                r'\.bashrc',
                r'\.profile',
                r'startup',
                r'registry'
            ]
        }
        
        # Signatures de payloads malveillants
        self.malicious_signatures = {
            'php_backdoor': r'<\?php.*system\s*\(',
            'jsp_shell': r'Runtime\.getRuntime\(\)\.exec',
            'python_reverse': r'socket\.connect.*subprocess',
            'bash_oneliner': r'bash\s+-i\s+>&\s+/dev/tcp',
            'powershell_b64': r'powershell.*-enc.*[A-Za-z0-9+/=]{50,}'
        }
    
    def analyze_script(self, script_content: str, script_language: str) -> Dict[str, Any]:
        """Analyse un script d'exploitation pour identifier les techniques"""
        print(f"üîç Analyse du script {script_language}...")
        
        analysis_result = {
            'script_language': script_language,
            'script_size': len(script_content),
            'attack_techniques': [],
            'malicious_indicators': [],
            'network_indicators': [],
            'file_indicators': [],
            'suspicious_commands': [],
            'risk_score': 0
        }
        
        # D√©tection des patterns d'attaque
        total_patterns = 0
        for category, patterns in self.attack_patterns.items():
            category_matches = []
            for pattern in patterns:
                matches = re.findall(pattern, script_content, re.IGNORECASE)
                if matches:
                    category_matches.extend(matches)
                    total_patterns += len(matches)
            
            if category_matches:
                analysis_result['attack_techniques'].append({
                    'category': category,
                    'matches': category_matches[:5],  # Limiter les r√©sultats
                    'count': len(category_matches)
                })
        
        # D√©tection des signatures malveillantes
        for sig_name, sig_pattern in self.malicious_signatures.items():
            if re.search(sig_pattern, script_content, re.IGNORECASE):
                analysis_result['malicious_indicators'].append(sig_name)
        
        # Extraction des indicateurs r√©seau
        ip_pattern = r'\b(?:[0-9]{1,3}\.){3}[0-9]{1,3}\b'
        port_pattern = r':\d{1,5}\b'
        url_pattern = r'https?://[^\s\'"<>]+'
        
        ips = re.findall(ip_pattern, script_content)
        ports = re.findall(port_pattern, script_content)
        urls = re.findall(url_pattern, script_content)
        
        analysis_result['network_indicators'] = {
            'ip_addresses': list(set(ips)),
            'ports': list(set(ports)),
            'urls': list(set(urls))
        }
        
        # Extraction des indicateurs de fichiers
        file_patterns = [
            r'/etc/[a-zA-Z0-9_.-]+',
            r'/var/[a-zA-Z0-9_./=-]+',
            r'/tmp/[a-zA-Z0-9_.-]+',
            r'[a-zA-Z0-9_.-]+\.(?:php|jsp|asp|exe|sh|py)'
        ]
        
        files = []
        for pattern in file_patterns:
            files.extend(re.findall(pattern, script_content))
        
        analysis_result['file_indicators'] = list(set(files))
        
        # Commandes suspectes
        command_patterns = [
            r'(?:sudo|su)\s+[^\n]+',
            r'chmod\s+[^\n]+',
            r'chown\s+[^\n]+',
            r'cat\s+/etc/[^\n]+',
            r'find\s+/.*-name[^\n]+',
            r'grep\s+-r[^\n]+'
        ]
        
        for pattern in command_patterns:
            commands = re.findall(pattern, script_content, re.IGNORECASE)
            analysis_result['suspicious_commands'].extend(commands)
        
        # Calcul du score de risque
        risk_score = 0
        risk_score += len(analysis_result['attack_techniques']) * 10
        risk_score += len(analysis_result['malicious_indicators']) * 20
        risk_score += len(analysis_result['network_indicators']['ip_addresses']) * 5
        risk_score += len(analysis_result['suspicious_commands']) * 3
        
        analysis_result['risk_score'] = min(risk_score, 100)  # Maximum 100
        
        print(f"  üìä Score de risque: {analysis_result['risk_score']}/100")
        print(f"  üéØ Techniques d√©tect√©es: {len(analysis_result['attack_techniques'])}")
        
        return analysis_result

    def extract_iocs(self, script_analysis: Dict[str, Any], execution_results: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Extrait les IoCs du script et des r√©sultats d'ex√©cution"""
        print("üö® Extraction des indicateurs de compromission...")
        
        iocs = []
        
        # IoCs des adresses IP
        for ip in script_analysis['network_indicators']['ip_addresses']:
            if not self._is_private_ip(ip):
                iocs.append({
                    'type': 'ip_address',
                    'value': ip,
                    'severity': 'HIGH',
                    'description': f'Adresse IP externe trouv√©e dans le script d\'exploitation',
                    'source': 'script_analysis'
                })
        
        # IoCs des URLs malveillantes
        for url in script_analysis['network_indicators']['urls']:
            iocs.append({
                'type': 'url',
                'value': url,
                'severity': 'MEDIUM',
                'description': f'URL trouv√©e dans le script d\'exploitation',
                'source': 'script_analysis'
            })
        
        # IoCs des fichiers suspects
        for file_path in script_analysis['file_indicators']:
            if any(danger in file_path.lower() for danger in ['/etc/', '/var/', '.php', '.jsp']):
                iocs.append({
                    'type': 'file_path',
                    'value': file_path,
                    'severity': 'MEDIUM',
                    'description': f'Fichier suspect acc√©d√©: {file_path}',
                    'source': 'script_analysis'
                })
        
        # IoCs des commandes suspectes
        for cmd in script_analysis['suspicious_commands'][:5]:  # Limiter
            iocs.append({
                'type': 'command',
                'value': cmd,
                'severity': 'HIGH',
                'description': f'Commande suspecte ex√©cut√©e',
                'source': 'script_analysis'
            })
        
        # IoCs des techniques d'attaque
        for technique in script_analysis['attack_techniques']:
            iocs.append({
                'type': 'attack_technique',
                'value': technique['category'],
                'severity': 'CRITICAL',
                'description': f'Technique d\'attaque identifi√©e: {technique["category"]}',
                'source': 'script_analysis'
            })
        
        print(f"  üö® {len(iocs)} IoCs extraits")
        return iocs

    def _is_private_ip(self, ip: str) -> bool:
        """V√©rifie si une IP est priv√©e"""
        private_ranges = [
            r'^10\.',
            r'^192\.168\.',
            r'^172\.(1[6-9]|2[0-9]|3[01])\.',
            r'^127\.',
            r'^169\.254\.'
        ]
        
        for range_pattern in private_ranges:
            if re.match(range_pattern, ip):
                return True
        return False

print("‚úÖ SecurityAnalyzer d√©fini")

# %%
# Agent Blue Team Principal
class BlueTeamAgent:
    """
    Agent Blue Team sp√©cialis√© dans l'analyse d√©fensive et la rem√©diation
    """
    
    def __init__(self, model_name: str = "llama2:7b"):
        print("üîµ Initialisation de BlueTeamAgent...")
        
        # Initialisation LLM
        self.llm = Ollama(model=model_name, temperature=0.2)  # Temp√©rature plus basse pour la pr√©cision
        
        # Analyseur de s√©curit√©
        self.security_analyzer = SecurityAnalyzer()
        
        # Parsers Pydantic
        self.defense_parser = PydanticOutputParser(pydantic_object=DefenseReport)
        
        # Configuration des prompts
        self._setup_prompts()
        
        print("  ‚úÖ BlueTeamAgent initialis√©")

    def _setup_prompts(self):
        """Configuration des prompts pour l'analyse d√©fensive"""
        
        # Prompt principal d'analyse d√©fensive
        defense_template = """Tu es un expert en cybers√©curit√© d√©fensive avec 15 ans d'exp√©rience en r√©ponse aux incidents.

ANALYSE DE L'ATTAQUE DU RED TEAM:
{attack_analysis}

SCRIPT D'EXPLOITATION ANALYS√â:
{script_analysis}

INDICATEURS DE COMPROMISSION D√âTECT√âS:
{iocs_detected}

R√âSULTATS D'EX√âCUTION:
{execution_results}

{format_instructions}

MISSION: Cr√©er un plan de d√©fense complet pour contrer cette attaque et pr√©venir de futures intrusions.

ANALYSE REQUISE:
1. √âvaluation de l'impact de l'attaque
2. Identification des failles de s√©curit√© exploit√©es
3. Recommandations de rem√©diation par priorit√©
4. R√®gles de d√©tection pour SIEM/IDS/WAF
5. Plan de durcissement du syst√®me
6. Timeline de rem√©diation

CONSID√âRATIONS SP√âCIALES:
- Prioriser les correctifs critiques
- Proposer des mesures temporaires si les correctifs prennent du temps
- Inclure des m√©triques de s√©curit√©
- Consid√©rer l'impact business des recommandations

RAPPORT DE D√âFENSE:"""

        self.defense_prompt = PromptTemplate(
            template=defense_template,
            input_variables=["attack_analysis", "script_analysis", "iocs_detected", "execution_results"],
            partial_variables={"format_instructions": self.defense_parser.get_format_instructions()}
        )
        
        # Cha√Æne LangChain
        self.defense_chain = LLMChain(llm=self.llm, prompt=self.defense_prompt)

    def analyze_red_team_attack(self, analysis_report: Dict[str, Any], 
                              exploitation_report: Dict[str, Any]) -> Dict[str, Any]:
        """Analyse compl√®te de l'attaque du Red Team"""
        print("üîç Analyse de l'attaque du Red Team...")
        
        # Extraction des informations d'attaque
        attack_info = {
            'vulnerability_exploited': analysis_report.get('analysis_report', {}).get('vulnerability_details', {}),
            'exploitation_strategy': exploitation_report.get('exploitation_report', {}).get('exploit_strategy', ''),
            'success_level': exploitation_report.get('exploitation_report', {}).get('success_level', 'UNKNOWN'),
            'attack_duration': exploitation_report.get('metadata', {}).get('execution_time', 0),
            'compromise_evidence': exploitation_report.get('exploitation_report', {}).get('compromise_evidence', [])
        }
        
        # Analyse du script d'exploitation
        generated_script = exploitation_report.get('exploitation_report', {}).get('generated_script', {})
        script_content = generated_script.get('script_content', '')
        script_language = generated_script.get('script_language', 'unknown')
        
        script_analysis = self.security_analyzer.analyze_script(script_content, script_language)
        
        # Ex√©cution des r√©sultats
        execution_results = exploitation_report.get('exploitation_report', {}).get('execution_results', {})
        
        # Extraction des IoCs
        iocs = self.security_analyzer.extract_iocs(script_analysis, execution_results)
        
        print(f"  üìä Niveau de succ√®s de l'attaque: {attack_info['success_level']}")
        print(f"  üö® IoCs d√©tect√©s: {len(iocs)}")
        print(f"  üéØ Score de risque du script: {script_analysis['risk_score']}/100")
        
        return {
            'attack_info': attack_info,
            'script_analysis': script_analysis,
            'iocs': iocs,
            'execution_results': execution_results
        }

    def generate_detection_rules(self, script_analysis: Dict[str, Any], iocs: List[Dict[str, Any]]) -> Dict[str, List[str]]:
        """G√©n√®re des r√®gles de d√©tection pour diff√©rents syst√®mes"""
        print("üõ°Ô∏è G√©n√©ration des r√®gles de d√©tection...")
        
        detection_rules = {
            'waf_rules': [],
            'ids_rules': [],
            'siem_rules': [],
            'endpoint_rules': []
        }
        
        # R√®gles WAF pour les attaques web
        for technique in script_analysis.get('attack_techniques', []):
            if technique['category'] == 'web_exploitation':
                detection_rules['waf_rules'].append(
                    f"SecRule ARGS \"@detectSQLi\" \"id:1001,phase:2,block,msg:'SQL Injection detected in {technique['category']}'\""
                )
                detection_rules['waf_rules'].append(
                    f"SecRule ARGS \"@contains ../\" \"id:1002,phase:2,block,msg:'Path traversal attempt detected'\""
                )
        
        # R√®gles IDS pour le trafic r√©seau
        for ip in script_analysis.get('network_indicators', {}).get('ip_addresses', []):
            if not self.security_analyzer._is_private_ip(ip):
                detection_rules['ids_rules'].append(
                    f"alert tcp any any -> {ip} any (msg:\"Traffic to suspicious IP {ip}\"; sid:2001; rev:1;)"
                )
        
        # R√®gles SIEM pour les logs
        for cmd in script_analysis.get('suspicious_commands', [])[:3]:
            detection_rules['siem_rules'].append(
                f"DeviceProduct=* AND CommandLine=\"*{cmd}*\" | eval threat_level=\"HIGH\""
            )
        
        # R√®gles endpoint pour les processus
        if 'reverse_shell' in [t['category'] for t in script_analysis.get('attack_techniques', [])]:
            detection_rules['endpoint_rules'].append(
                "ProcessName=*sh OR ProcessName=*cmd.exe AND CommandLine=\"*/dev/tcp/*\""
            )
            detection_rules['endpoint_rules'].append(
                "NetworkConnection AND DestinationPort IN (4444,1234,9999) AND Direction=Outbound"
            )
        
        total_rules = sum(len(rules) for rules in detection_rules.values())
        print(f"  üõ°Ô∏è {total_rules} r√®gles de d√©tection g√©n√©r√©es")
        
        return detection_rules

    def create_remediation_plan(self, attack_analysis: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Cr√©e un plan de rem√©diation d√©taill√©"""
        print("üìã Cr√©ation du plan de rem√©diation...")
        
        recommendations = []
        
        # Analyse de la vuln√©rabilit√© principale
        vuln_details = attack_analysis['attack_info']['vulnerability_exploited']
        cve = vuln_details.get('cve', '')
        attack_type = vuln_details.get('attack_type', '')
        
        # Recommandations bas√©es sur le type d'attaque
        if 'Path Traversal' in attack_type or 'Directory Traversal' in attack_type:
            recommendations.append({
                'category': 'PATCH',
                'priority': 'IMMEDIATE',
                'title': 'Correction de la vuln√©rabilit√© Path Traversal',
                'description': f'Appliquer le patch de s√©curit√© pour {cve}',
                'implementation_steps': [
                    'Identifier la version exacte du logiciel affect√©',
                    'T√©l√©charger le patch de s√©curit√© officiel',
                    'Tester le patch en environnement de d√©veloppement',
                    'Planifier une fen√™tre de maintenance',
                    'Appliquer le patch en production',
                    'V√©rifier que la vuln√©rabilit√© est corrig√©e'
                ],
                'estimated_effort': '2-4 heures',
                'risk_reduction': 90
            })
            
            recommendations.append({
                'category': 'CONFIGURATION',
                'priority': 'HIGH',
                'title': 'Durcissement de la configuration web',
                'description': 'Configurer le serveur web pour bloquer les tentatives de path traversal',
                'implementation_steps': [
                    'Configurer le serveur web pour bloquer les s√©quences "../"',
                    'Impl√©menter une liste blanche de fichiers accessibles',
                    'Activer les logs d√©taill√©s des tentatives d\'acc√®s',
                    'Configurer des r√©pertoires en lecture seule'
                ],
                'estimated_effort': '1-2 heures',
                'risk_reduction': 70
            })
        
        if 'Remote Code Execution' in attack_type or 'RCE' in attack_type:
            recommendations.append({
                'category': 'PATCH',
                'priority': 'IMMEDIATE',
                'title': 'Correction critique de RCE',
                'description': f'Correction imm√©diate de la vuln√©rabilit√© RCE {cve}',
                'implementation_steps': [
                    'Isoler imm√©diatement le service affect√©',
                    'Appliquer le patch de s√©curit√© critique',
                    'Red√©marrer les services concern√©s',
                    'V√©rifier l\'int√©grit√© du syst√®me',
                    'Analyser les logs pour des traces d\'exploitation'
                ],
                'estimated_effort': '1-3 heures',
                'risk_reduction': 95
            })
        
        # Recommandations bas√©es sur les techniques d√©tect√©es
        attack_techniques = [t['category'] for t in attack_analysis['script_analysis'].get('attack_techniques', [])]
        
        if 'reverse_shell' in attack_techniques:
            recommendations.append({
                'category': 'NETWORK',
                'priority': 'HIGH',
                'title': 'Blocage des connexions sortantes suspectes',
                'description': 'Configurer le firewall pour bloquer les connexions sortantes non autoris√©es',
                'implementation_steps': [
                    'Identifier les ports utilis√©s pour les reverse shells',
                    'Configurer des r√®gles de firewall sortant restrictives',
                    'Mettre en place une surveillance des connexions sortantes',
                    'Alerter sur les tentatives de connexion vers des IPs externes'
                ],
                'estimated_effort': '30-60 minutes',
                'risk_reduction': 60
            })
        
        if 'command_injection' in attack_techniques:
            recommendations.append({
                'category': 'CONFIGURATION',
                'priority': 'HIGH',
                'title': 'Durcissement contre l\'injection de commandes',
                'description': 'Renforcer la validation des entr√©es et l\'isolation des processus',
                'implementation_steps': [
                    'Impl√©menter une validation stricte des entr√©es utilisateur',
                    'Utiliser des fonctions s√©curis√©es pour l\'ex√©cution de commandes',
                    'Mettre en place une sandbox pour les processus web',
                    'Limiter les privil√®ges des comptes de service'
                ],
                'estimated_effort': '4-8 heures',
                'risk_reduction': 85
            })
        
        # Recommandations de surveillance
        recommendations.append({
            'category': 'MONITORING',
            'priority': 'MEDIUM',
            'title': 'Am√©lioration de la surveillance de s√©curit√©',
            'description': 'Mettre en place une surveillance avanc√©e pour d√©tecter les attaques similaires',
            'implementation_steps': [
                'D√©ployer des r√®gles de d√©tection dans le SIEM',
                'Configurer des alertes temps r√©el',
                'Mettre en place des tableaux de bord de s√©curit√©',
                'Former l\'√©quipe aux nouveaux indicateurs'
            ],
            'estimated_effort': '1-2 jours',
            'risk_reduction': 40
        })
        
        print(f"  üìã {len(recommendations)} recommandations cr√©√©es")
        return recommendations

    def calculate_risk_metrics(self, attack_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """Calcule les m√©triques de risque et KPI"""
        print("üìä Calcul des m√©triques de risque...")
        
        # Score de base selon le succ√®s de l'attaque
        success_level = attack_analysis['attack_info']['success_level']
        base_risk = {
            'FULL': 100,
            'PARTIAL': 70,
            'FAILED': 30
        }.get(success_level, 50)
        
        # Facteurs de risque suppl√©mentaires
        script_risk = attack_analysis['script_analysis']['risk_score']
        ioc_count = len(attack_analysis['iocs'])
        technique_count = len(attack_analysis['script_analysis'].get('attack_techniques', []))
        
        # Calcul du risque global
        risk_factors = {
            'exploitation_success': base_risk * 0.4,
            'script_complexity': script_risk * 0.3,
            'ioc_severity': min(ioc_count * 5, 50) * 0.2,
            'technique_diversity': min(technique_count * 10, 50) * 0.1
        }
        
        total_risk = sum(risk_factors.values())
        
        # Classification du risque
        if total_risk >= 80:
            risk_level = 'CRITICAL'
        elif total_risk >= 60:
            risk_level = 'HIGH'
        elif total_risk >= 40:
            risk_level = 'MEDIUM'
        else:
            risk_level = 'LOW'
        
        # M√©triques additionnelles
        cvss_score = None
        vuln_details = attack_analysis['attack_info']['vulnerability_exploited']
        if 'cvss_score' in vuln_details:
            try:
                cvss_score = float(vuln_details['cvss_score'])
            except:
                pass
        
        metrics = {
            'overall_risk_score': round(total_risk, 1),
            'risk_level': risk_level,
            'risk_factors': risk_factors,
            'cvss_score': cvss_score,
            'attack_success_rate': base_risk,
            'ioc_count': ioc_count,
            'technique_count': technique_count,
            'estimated_recovery_time': self._estimate_recovery_time(total_risk),
            'business_impact': self._assess_business_impact(total_risk, success_level)
        }
        
        print(f"  üìä Risque global: {total_risk:.1f}/100 ({risk_level})")
        return metrics

    def _estimate_recovery_time(self, risk_score: float) -> str:
        """Estime le temps de r√©cup√©ration bas√© sur le score de risque"""
        if risk_score >= 80:
            return "24-48 heures"
        elif risk_score >= 60:
            return "8-24 heures"
        elif risk_score >= 40:
            return "4-8 heures"
        else:
            return "1-4 heures"

    def _assess_business_impact(self, risk_score: float, success_level: str) -> str:
        """√âvalue l'impact business"""
        if success_level == 'FULL' and risk_score >= 80:
            return "SEVERE - Arr√™t potentiel des op√©rations"
        elif success_level == 'FULL' and risk_score >= 60:
            return "HIGH - Impact significatif sur les op√©rations"
        elif success_level == 'PARTIAL':
            return "MEDIUM - Impact limit√© mais surveillance requise"
        else:
            return "LOW - Impact minimal"

    def generate_defense_report(self, attack_analysis: Dict[str, Any]) -> DefenseReport:
        """G√©n√®re le rapport de d√©fense complet avec le LLM"""
        print("üìã G√©n√©ration du rapport de d√©fense avec LLM...")
        
        try:
            # Pr√©paration des donn√©es pour le LLM
            defense_result = self.defense_chain.run(
                attack_analysis=json.dumps(attack_analysis['attack_info'], indent=2),
                script_analysis=json.dumps(attack_analysis['script_analysis'], indent=2),
                iocs_detected=json.dumps(attack_analysis['iocs'], indent=2),
                execution_results=json.dumps(attack_analysis['execution_results'], indent=2)
            )
            
            # Parsing avec Pydantic
            defense_report = self.defense_parser.parse(defense_result)
            
            print("  ‚úÖ Rapport de d√©fense g√©n√©r√© avec LLM")
            return defense_report
            
        except Exception as e:
            print(f"  ‚ö† Erreur g√©n√©ration LLM: {e}, utilisation du fallback...")
            
            # G√©n√©ration manuelle en cas d'√©chec LLM
            detection_rules = self.generate_detection_rules(
                attack_analysis['script_analysis'], 
                attack_analysis['iocs']
            )
            
            recommendations = self.create_remediation_plan(attack_analysis)
            risk_metrics = self.calculate_risk_metrics(attack_analysis)
            
            # Conversion des IoCs au format Pydantic
            pydantic_iocs = []
            for ioc in attack_analysis['iocs']:
                pydantic_iocs.append(IndicatorOfCompromise(
                    ioc_type=ioc['type'],
                    value=ioc['value'],
                    severity=ioc['severity'],
                    description=ioc['description'],
                    detection_rule=f"Monitor for {ioc['type']}: {ioc['value']}"
                ))
            
            # Conversion des recommandations
            pydantic_recommendations = []
            for rec in recommendations:
                pydantic_recommendations.append(DefenseRecommendation(**rec))
            
            return DefenseReport(
                attack_analysis=attack_analysis['attack_info'],
                indicators_of_compromise=pydantic_iocs,
                defense_recommendations=pydantic_recommendations,
                detection_rules=detection_rules,
                risk_assessment=risk_metrics,
                remediation_timeline={
                    'immediate': [r.title for r in pydantic_recommendations if r.priority == 'IMMEDIATE'],
                    'high': [r.title for r in pydantic_recommendations if r.priority == 'HIGH'],
                    'medium': [r.title for r in pydantic_recommendations if r.priority == 'MEDIUM']
                }
            )

    def run(self, analysis_report_path: str, exploitation_report_path: str) -> Dict[str, Any]:
        """M√©thode principale de l'agent Blue Team"""
        print(f"\n{'üîµ'*20}")
        print(f"üîµ D√âMARRAGE DE L'AGENT BLUE TEAM")
        print(f"{'üîµ'*20}")
        
        start_time = time.time()
        
        try:
            # Chargement des rapports
            print("\nüìñ [1/4] Chargement des rapports Red Team...")
            
            with open(analysis_report_path, 'r') as f:
                analysis_report = json.load(f)
            
            with open(exploitation_report_path, 'r') as f:
                exploitation_report = json.load(f)
            
            # Analyse de l'attaque
            print("\nüîç [2/4] Analyse de l'attaque Red Team...")
            attack_analysis = self.analyze_red_team_attack(analysis_report, exploitation_report)
            
            # G√©n√©ration du rapport de d√©fense
            print("\nüõ°Ô∏è [3/4] G√©n√©ration du plan de d√©fense...")
            defense_report = self.generate_defense_report(attack_analysis)
            
            # Finalisation
            print("\nüìã [4/4] Finalisation du rapport...")
            
            total_time = time.time() - start_time
            
            complete_result = {
                "metadata": {
                    "agent": "BlueTeamAgent",
                    "version": "2.0",
                    "timestamp": datetime.now().isoformat(),
                    "execution_time": total_time,
                    "analysis_source": analysis_report_path,
                    "exploitation_source": exploitation_report_path
                },
                "defense_report": defense_report.dict(),
                "status": "SUCCESS"
            }
            
            # Sauvegarde du rapport
            report_file = "defense_report.json"
            with open(report_file, 'w') as f:
                json.dump(complete_result, f, indent=2)
            
            print(f"\n‚úÖ ANALYSE D√âFENSIVE TERMIN√âE")
            print(f"‚è±Ô∏è Temps total: {total_time:.2f} secondes")
            print(f"üö® IoCs d√©tect√©s: {len(defense_report.indicators_of_compromise)}")
            print(f"üõ°Ô∏è Recommandations: {len(defense_report.defense_recommendations)}")
            print(f"üìä Niveau de risque: {defense_report.risk_assessment.get('risk_level', 'UNKNOWN')}")
            print(f"üíæ Rapport sauvegard√©: {report_file}")
            
            return complete_result
            
        except Exception as e:
            print(f"\n‚ùå ERREUR DANS L'ANALYSE D√âFENSIVE: {e}")
            return {
                "metadata": {
                    "agent": "BlueTeamAgent",
                    "timestamp": datetime.now().isoformat()
                },
                "status": "ERROR",
                "error": str(e)
            }

print("‚úÖ BlueTeamAgent complet d√©fini")

# %%
# D√©monstration et test de l'agent Blue Team
if __name__ == "__main__":
    print(f"\nüß™ D√âMONSTRATION DE L'AGENT BLUE TEAM")
    print("="*50)
    
    # Chargement de la configuration
    try:
        with open("vple_config.json", "r") as f:
            config = json.load(f)
        model_name = config.get("confirmed_model", "llama2:7b")
    except:
        model_name = "llama2:7b"
    
    # Initialisation de l'agent
    blue_team_agent = BlueTeamAgent(model_name=model_name)
    
    # V√©rification de l'existence des rapports
    analysis_report_path = "analysis_report.json"
    exploitation_report_path = "exploitation_report.json"
    
    if os.path.exists(analysis_report_path) and os.path.exists(exploitation_report_path):
        print("üìÑ Rapports Red Team trouv√©s, lancement de l'analyse...")
        
        # Test de l'agent
        result = blue_team_agent.run(analysis_report_path, exploitation_report_path)
        
        if result['status'] == 'SUCCESS':
            defense_report = result['defense_report']
            print(f"\n‚úÖ Test r√©ussi!")
            print(f"   IoCs: {len(defense_report['indicators_of_compromise'])}")
            print(f"   Recommandations: {len(defense_report['defense_recommendations'])}")
            print(f"   Risque: {defense_report['risk_assessment'].get('risk_level', 'UNKNOWN')}")
        else:
            print(f"\n‚ùå Test √©chou√©: {result.get('error', 'Erreur inconnue')}")
    
    else:
        print("‚ö† Rapports Red Team non trouv√©s, cr√©ation de donn√©es fictives...")
        
        # Cr√©ation de rapports fictifs pour test
        fake_analysis = {
            "analysis_report": {
                "vulnerability_details": {
                    "cve": "CVE-2021-41773",
                    "attack_type": "Path Traversal to RCE",
                    "cvss_score": "7.5"
                }
            }
        }
        
        fake_exploitation = {
            "exploitation_report": {
                "exploit_strategy": "Path traversal combined with log poisoning",
                "generated_script": {
                    "script_content": "import requests\nrequests.get('http://target/../../../etc/passwd')",
                    "script_language": "python"
                },
                "execution_results": {"return_code": 0},
                "success_level": "PARTIAL",
                "compromise_evidence": ["Script executed successfully"]
            }
        }
        
        with open(analysis_report_path, 'w') as f:
            json.dump(fake_analysis, f, indent=2)
        
        with open(exploitation_report_path, 'w') as f:
            json.dump(fake_exploitation, f, indent=2)
        
        print("üìù Rapports fictifs cr√©√©s, test de l'agent...")
        
        result = blue_team_agent.run(analysis_report_path, exploitation_report_path)
        
        if result['status'] == 'SUCCESS':
            print(f"‚úÖ Test avec donn√©es fictives r√©ussi!")
        else:
            print(f"‚ùå Test √©chou√©: {result.get('error', 'Erreur inconnue')}")
    
    print(f"\nüéâ D√âMONSTRATION TERMIN√âE")
    print("L'agent Blue Team est pr√™t pour l'orchestrateur!")
